---
layout: post
title:  "IRT模型中的项目信息函数解读"
date:   2022-02-15 10:04:08 +0800
tags: 智能教育
---

之前一直困惑于IRT模型的项目信息函数的含义。看了李政轩老师的[Item and Test Information Function](https://www.youtube.com/watch?v=VBoZ3bVapbw)视频，总算搞清楚了。这里做一个简要的记录。

基本的IRT相关的知识，可以参考[维基百科-IRT](https://zh.wikipedia.org/wiki/%E9%A1%B9%E7%9B%AE%E5%8F%8D%E5%BA%94%E7%90%86%E8%AE%BA)。


假设已知abc$\theta$四个参数的值，那么就可以计算出用户做此题正确的概率$\bar{P}$。

根据这个正确概率进行n次模拟，模拟过程如下，随机产生一个0-1的数，小于$\bar{P}$代表做对，大于代表做错。

根据模拟得到的n次做答记录，对$\theta$进行极大似然估计，可以求出一个$\hat{\theta}$。

将上述过程重复m次，那么就可以得到m个$\hat{\theta}$的值。

观察m个$\hat{\theta}$的均值和标准差SE。显然其均值应很接近真实的能力$\theta$，因为模拟的依据就是$\theta$。

观察SE可以得到两个结论，**$\theta$和b越接近，SE越小，a越大，SE越小**。

这两个观察出的结论非常重要，它实际告诉了我们衡量一道题目和一个用户的匹配程度的简单方法，就是看SE，SE越小，越匹配。

厉害的是，SE竟然是有解析解的，公式如下：
{% raw %}
$$
\frac{1}{\sqrt{\sum\limits_{i=1}^{n}\frac{{P_i^{'}(\theta)}^2}{P_i(\theta)(1-P_i(\theta))}}}
$$
{% endraw %}
这是对n次模拟来说的SE，观察这个解析式，可以发现，要SE越小，相当于让每道题的：
{% raw %}

$$
\frac{{P_i^{'}(\theta)}^2}{P_i(\theta)(1-P_i(\theta))}
$$
{% endraw %}

这个值越大。

而这个值，就是项目信息函数。

对该项目信息函数还可以进一步求出上面的导数化简，得到：
{% raw %}
$$
a_i^2P_i(\theta)(1-P_i(\theta))
$$
{% endraw %}

这个公式的含义更加清晰。







