---
layout: post
title:  "BLEU的计算"
date:   2022-06-06 09:20:08 +0800
category: "AI"
published: true
---

介绍一下BLEU的计算原理。

<!--more-->


BLEU是机器翻译的衡量指标，它的设计初衷就是比较机器翻译的句子和人工翻译的句子之间的重合度。

我们先给出整体的计算公式，然后从里往外分步解释各个组成成分的含义。

$$
BLEU = BP \times exp\big(\sum_{n=1}^{N}W_nlogP_n\big)
$$

# $P_n$
$P_n$表示的是机器翻译的句子和人工翻译的句子，在n-gram这个层面上的重合度。

公式如下：

$$
P_n = \frac{\sum_i\sum_kmin(h_k(c_i), max_{j\in m}h_k(s_{ij}))}{\sum_i\sum_kh_k(c_i)}
$$

i 表示的第i个句子，因为一般评测时，有多个句子，所以需要将多个句子的评估结果合并起来考虑。

k表示机器翻译的句子中的第k个n-gram。

也就是说我们要遍历每个机器翻译的句子，对每个机器翻译的句子，遍历它所有的n-gram。

$h_k(.)$表示的是某个句子中第k个n-gram出现的次数。

上面公式的分母就是机器翻译的句子中所有n-gram出现的次数的总和。

分子含义类似，但是，对次数做了一个修正，考虑到了标准答案的句子中的n-gram出现的次数，它和机器翻译的句子的n-gram的次数比较，二者取最小值。

这主要是为了防止机器通过重复输出一个n-gram，从而获得过高的BLEU值的情况。

比如，机器翻译的是：the the the the。
标准答案是：the boy is in the house。

从1-gram的角度看，机器翻译的4个1-gram都在标准答案中出现了。
覆盖率是1。但显然，这并不合实际。因为标准答案中只出现了2次the，所以我们要对the这个1-ngram进行修正。方法就是上面的公式中的内容。

# $W_n$

$W_n$的目的是对不同长度的n-gram的$P_n$进行加权。假设一共统计了 1-4的n-gram，那么， $W_n$就是1/4。

# $BP$
BP是从句子的长度比较上，进行加权。基本思想是，如果翻译的句子比标准答案的句子短，就要进行相应的惩罚。
其计算公式为：

$$
BP = \Biggl \{^{1 \quad if \quad lc > ls}_{e^{1-\frac{ls}{lc}} \quad if \quad lc \leq ls}
$$


以上就是BLEU计算的基本原理，还是非常直观的。





